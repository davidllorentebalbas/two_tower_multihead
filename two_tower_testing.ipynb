{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e8c133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DLLOREN/Library/CloudStorage/OneDrive-Mercedes-Benz(corpdir.onmicrosoft.com)/Desktop/tfgUVA/two_tower_model_ibs/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tabulate\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from src.models import TwoTowerRecommendationModel, TwoTowerRecommendationModel_MLP\n",
    "from src.utils import generate_random_sample_data\n",
    "from src.movie_dataset_utils import load_data, gen_user_vecs\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pd.set_option(\"display.precision\", 1)\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b455a1",
   "metadata": {},
   "source": [
    "### Content-based filtering with a Two Tower neural network\n",
    "\n",
    "<figure>\n",
    "    <center> <img src=\"images/RecSysNN.png\"   style=\"width:500px;height:280px;\" ></center>\n",
    "</figure>\n",
    "\n",
    "The Two-Tower model is a neural network architecture used for recommendation systems. It consists of two separate neural networks (towers) that learn user and item representations independently. The user tower processes user features, while the item tower processes item features. The outputs of these towers are then combined, typically using a similarity measure like cosine similarity, to predict the relevance score or rating for a given user-item pair. This model allows for efficient retrieval of recommendations by precomputing item representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac88f2a",
   "metadata": {},
   "source": [
    "\n",
    "## Movie ratings dataset \n",
    "The data set is derived from the [MovieLens ml-latest-small](https://grouplens.org/datasets/movielens/latest/) dataset. \n",
    "\n",
    "[F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4: 19:1â€“19:19. <https://doi.org/10.1145/2827872>]\n",
    "\n",
    "The original dataset has 9000 movies rated by 600 users with ratings on a scale of 0.5 to 5 in 0.5 step increments. The dataset has been reduced in size to focus on movies from the years since 2000 and popular genres. The reduced dataset has $n_u = 395$ users and $n_m= 694$ movies. For each movie, the dataset provides a movie title, release date, and one or more genres. For example \"Toy Story 3\" was released in 2010 and has several genres: \"Adventure|Animation|Children|Comedy|Fantasy|IMAX\".  This dataset contains little information about users other than their ratings. This dataset is used to create training vectors for the neural networks described below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c69bd461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data, set configuration variables\n",
    "    \n",
    "cwd = os.getcwd()\n",
    "path = os.path.join(cwd, \"data/gold/movie_dataset/\")\n",
    "item_train, user_train, y_train, item_features, user_features, item_vecs, movie_dict, user_to_genre = load_data(path=path)\n",
    "\n",
    "add_movie_descriptions_embeddings = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ef501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if add_movie_descriptions_embeddings:\n",
    "        # Embed movie descriptions using SentenceTransformer with all-MiniLM-L6-v2 transformer model\n",
    "        # This creates 384 dimensional embeddings for each movie description\n",
    "        model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "        movie_descripions = {movie_id:content['title'] + \" \" + content['genres'] for movie_id, content in movie_dict.items()}\n",
    "        movie_descripions_sentences = [movie_descripions[movie_id] for movie_id in movie_dict.keys()]\n",
    "        movies_embeddings = model.encode(movie_descripions_sentences)\n",
    "        \n",
    "        # Use PCA to reduce the embeddings dimensions with 0.95 variance\n",
    "        pca = PCA(n_components=0.95)    \n",
    "        movies_embeddings = pca.fit_transform(movies_embeddings)\n",
    "        movies_embeddings_dict = {movie_id:embeddings for movie_id, embeddings in zip(movie_dict.keys(), movies_embeddings)}\n",
    "        \n",
    "        # add embeddings to item_train\n",
    "        items_train_embeddings_to_add = []\n",
    "        for i in range(item_train.shape[0]):\n",
    "            movie_id = int(item_train[i, 0])\n",
    "            embeddings = movies_embeddings_dict[movie_id]\n",
    "            items_train_embeddings_to_add.append(embeddings)\n",
    "\n",
    "        # add embeddings to item_vecs\n",
    "        items_vecs_to_add = []\n",
    "        for i in range(item_vecs.shape[0]):\n",
    "            movie_id = int(item_vecs[i, 0])\n",
    "            embeddings = movies_embeddings_dict[movie_id]\n",
    "            items_vecs_to_add.append(embeddings)\n",
    "        \n",
    "        # Add embeddings to item_vecs\n",
    "        item_vecs = np.hstack((item_vecs, np.array(items_vecs_to_add)))\n",
    "        \n",
    "        # Add embeddings to item_train\n",
    "        item_train = np.hstack((item_train, np.array(items_train_embeddings_to_add)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d685e0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training vectors: 58187\n"
     ]
    }
   ],
   "source": [
    "num_user_features = user_train.shape[1] - 3  # remove userid, rating count and ave rating during training\n",
    "num_item_features = item_train.shape[1] - 1  # remove movie id at train time\n",
    "uvs = 3  # user genre vector start\n",
    "ivs = 3  # item genre vector start\n",
    "u_s = 3  # start of columns to use in training, user\n",
    "i_s = 1  # start of columns to use in training, items\n",
    "scaledata = True  # applies the standard scalar to data if true\n",
    "print(f\"Number of training vectors: {len(item_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ec26977",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_synthetic_data = False\n",
    "if use_synthetic_data:\n",
    "    # Generate synthetic data\n",
    "    num_samples = 1000\n",
    "    user_data, product_data, target_data = generate_random_sample_data(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1d0bfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "scaledata = True\n",
    "if scaledata:\n",
    "    item_train_save = item_train\n",
    "    user_train_save = user_train\n",
    "    y_train_save = y_train\n",
    "\n",
    "    scalerItem = StandardScaler()\n",
    "    scalerItem.fit(item_train)\n",
    "    item_train = scalerItem.transform(item_train)\n",
    "\n",
    "    scalerUser = StandardScaler()\n",
    "    scalerUser.fit(user_train)\n",
    "    user_train = scalerUser.transform(user_train)\n",
    "    \n",
    "    targetScaler = MinMaxScaler((-1, 1))\n",
    "    targetScaler.fit(y_train.reshape(-1, 1))\n",
    "    y_train = targetScaler.transform(y_train.reshape(-1, 1))\n",
    "\n",
    "    print(np.allclose(item_train_save, scalerItem.inverse_transform(item_train)))\n",
    "    print(np.allclose(user_train_save, scalerUser.inverse_transform(user_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21e237eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Tensor torch.Size([58187, 14]) Product Tensor torch.Size([58187, 16]) Target Rating Tensor torch.Size([58187, 1])\n"
     ]
    }
   ],
   "source": [
    "user_data_tensor = torch.tensor(user_train[:, u_s:], dtype=torch.float32)\n",
    "product_data_tensor = torch.tensor(item_train[:, i_s:], dtype=torch.float32)\n",
    "target_data_tensor = torch.tensor(y_train.reshape(-1,1), dtype=torch.float32) \n",
    "    \n",
    "print(\"User Tensor\", user_data_tensor.shape, \n",
    "      \"Product Tensor\", product_data_tensor.shape, \n",
    "      \"Target Rating Tensor\", target_data_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a79ea35e",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Hyperparameters\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "learning_rate = 0.001\n",
    "use_gpu = True\n",
    "\n",
    "# Model configurations\n",
    "user_config = {'input_dim': user_data_tensor.shape[1], \n",
    "            'embed_dim': 128,\n",
    "            'output_dim': 64, \n",
    "            'nr_heads': 8, \n",
    "            'continuous_feature_indices':[i for i in range(user_data_tensor.shape[1])],\n",
    "            'categorical_feature_indices': [], \n",
    "            'internal_dimension':32 # Internal Dimension for Continuous Features Embedding\n",
    "            }\n",
    "# product_config = {'input_dim': product_data_tensor.shape[1], \n",
    "#                 'embed_dim': 128, \n",
    "#                 'output_dim': 64,\n",
    "#                 'nr_heads': 8}\n",
    "product_config = {'input_dim': product_data_tensor.shape[1], \n",
    "        'embed_dim': 128,\n",
    "        'output_dim': 64, \n",
    "        'nr_heads': 8, \n",
    "        'continuous_feature_indices':[i for i in range(product_data_tensor.shape[1])], # Embeddings start at index 17\n",
    "        'categorical_feature_indices': [],#[i for i in range(0, 16)], # 16 is the number of genre features\n",
    "        'internal_dimension': 32 # Internal Dimension for Continuous Features Embedding\n",
    "        }\n",
    "        \n",
    "user_config_mlp = {'input_dim': user_data_tensor.shape[1], \n",
    "            'embed_dim': 128,\n",
    "            'output_dim': 64}\n",
    "product_config_mlp = {'input_dim': product_data_tensor.shape[1], \n",
    "                'embed_dim': 128, \n",
    "                'output_dim': 64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dc75c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/DLLOREN/Library/CloudStorage/OneDrive-Mercedes-Benz(corpdir.onmicrosoft.com)/Desktop/tfgUVA/two_tower_model_ibs/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "\n",
      "  | Name          | Type         | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | user_tower    | UserTower    | 134 K  | train\n",
      "1 | product_tower | ProductTower | 142 K  | train\n",
      "2 | criterion     | MSELoss      | 0      | train\n",
      "-------------------------------------------------------\n",
      "277 K     Trainable params\n",
      "0         Non-trainable params\n",
      "277 K     Total params\n",
      "1.109     Total estimated model params size (MB)\n",
      "163       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DLLOREN/Library/CloudStorage/OneDrive-Mercedes-Benz(corpdir.onmicrosoft.com)/Desktop/tfgUVA/two_tower_model_ibs/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DLLOREN/Library/CloudStorage/OneDrive-Mercedes-Benz(corpdir.onmicrosoft.com)/Desktop/tfgUVA/two_tower_model_ibs/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/DLLOREN/Library/CloudStorage/OneDrive-Mercedes-Benz(corpdir.onmicrosoft.com)/Desktop/tfgUVA/two_tower_model_ibs/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1455/1455 [01:25<00:00, 17.00it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DLLOREN/Library/CloudStorage/OneDrive-Mercedes-Benz(corpdir.onmicrosoft.com)/Desktop/tfgUVA/two_tower_model_ibs/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([21, 1])) that is different to the input size (torch.Size([21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1455/1455 [01:31<00:00, 15.92it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DLLOREN/Library/CloudStorage/OneDrive-Mercedes-Benz(corpdir.onmicrosoft.com)/Desktop/tfgUVA/two_tower_model_ibs/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([22, 1])) that is different to the input size (torch.Size([22])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1455/1455 [01:27<00:00, 16.60it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1455/1455 [01:27<00:00, 16.58it/s, v_num=0]\n",
      "Training Loss: 0.1006450206041336\n",
      "Validation Loss: 0.18948660790920258\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoader\n",
    "dataset = TensorDataset(user_data_tensor, product_data_tensor, target_data_tensor)\n",
    "num_samples = target_data_tensor.shape[0]\n",
    "train_size = int(0.8 * num_samples)\n",
    "test_size = num_samples - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4)\n",
    "\n",
    "# Initialize model\n",
    "model_type = \"multihead\" # \"multihead\" or \"mlp\"\n",
    "if model_type == \"multihead\":\n",
    "    model = TwoTowerRecommendationModel(user_config, product_config, learning_rate)\n",
    "elif model_type == \"mlp\":\n",
    "    model = TwoTowerRecommendationModel_MLP(user_config_mlp, product_config_mlp, learning_rate)\n",
    "\n",
    "\n",
    "if not use_gpu:\n",
    "\n",
    "    # Train the model\n",
    "    trainer = pl.Trainer(max_epochs=epochs)\n",
    "    trainer.fit(model, train_loader, test_loader)\n",
    "\n",
    "else:\n",
    "    # Move model to GPU if available\n",
    "    device = torch.device('mps' if torch.cuda.is_available() else 'mps')\n",
    "    model.to(device)\n",
    "\n",
    "    # Train the model on GPU\n",
    "    trainer = pl.Trainer(max_epochs=epochs, accelerator=\"gpu\", devices=1)\n",
    "    trainer.fit(model, train_loader, test_loader)\n",
    "\n",
    "# Print the model loss\n",
    "print(f\"Training Loss: {trainer.callback_metrics['train_loss']}\")\n",
    "print(f\"Validation Loss: {trainer.callback_metrics['val_loss']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbd6dde",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d018aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Vector Shape (1883, 1)\n"
     ]
    }
   ],
   "source": [
    "#Parameters definition\n",
    "\n",
    "new_user_id = 5000\n",
    "new_rating_ave = 1.0\n",
    "new_action = 1.0\n",
    "new_adventure = 1\n",
    "new_animation = 1\n",
    "new_childrens = 1\n",
    "new_comedy = 5\n",
    "new_crime = 1\n",
    "new_documentary = 1\n",
    "new_drama = 1\n",
    "new_fantasy = 1\n",
    "new_horror = 1\n",
    "new_mystery = 1\n",
    "new_romance = 5\n",
    "new_scifi = 5\n",
    "new_thriller = 1\n",
    "new_rating_count = 3\n",
    "\n",
    "user_vec = np.array([[new_user_id, new_rating_count, new_rating_ave,\n",
    "                    new_action, new_adventure, new_animation, new_childrens,\n",
    "                    new_comedy, new_crime, new_documentary,\n",
    "                    new_drama, new_fantasy, new_horror, new_mystery,\n",
    "                    new_romance, new_scifi, new_thriller]])\n",
    "\n",
    "user_vecs = gen_user_vecs(user_vec,len(item_vecs))\n",
    "    \n",
    "if scaledata:\n",
    "    scaled_user_vecs = scalerUser.transform(user_vecs)\n",
    "    scaled_item_vecs = scalerItem.transform(item_vecs)\n",
    "    user_data_tensor = torch.tensor(scaled_user_vecs[:, u_s:], dtype=torch.float32)\n",
    "    product_data_tensor = torch.tensor(scaled_item_vecs[:, i_s:], dtype=torch.float32)\n",
    "    y_p = model(user_data_tensor, product_data_tensor).detach().numpy()\n",
    "    y_p = targetScaler.inverse_transform(y_p.reshape(-1, 1))\n",
    "else:\n",
    "    y_p = model(user_vecs[:, u_s:], item_vecs[:, i_s:])\n",
    "        \n",
    "if np.any(y_p < 0) : \n",
    "    print(\"Error, expected all positive predictions\")\n",
    "    \n",
    "print(\"Prediction Vector Shape\", y_p.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62dcc479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   y_p  movie id  rating ave  \\\n",
      "0  3.6     55721         4.3   \n",
      "1  3.6     55442         4.2   \n",
      "2  3.6     57669         4.2   \n",
      "3  3.6     64716         4.1   \n",
      "4  3.6     71899         4.2   \n",
      "5  3.6     48516         4.3   \n",
      "6  3.6     55118         4.0   \n",
      "7  3.6     44555         4.1   \n",
      "8  3.6     57504         4.1   \n",
      "9  3.6     68954         4.0   \n",
      "\n",
      "                                               title  \\\n",
      "0                Elite Squad (Tropa de Elite) (2007)   \n",
      "1                                  Persepolis (2007)   \n",
      "2                                   In Bruges (2008)   \n",
      "3                                Seven Pounds (2008)   \n",
      "4                                Mary and Max (2009)   \n",
      "5                               Departed, The (2006)   \n",
      "6                            Eastern Promises (2007)   \n",
      "7  Lives of Others, The (Das leben der Anderen) (...   \n",
      "8  Girl Who Leapt Through Time, The (Toki o kaker...   \n",
      "9                                          Up (2009)   \n",
      "\n",
      "                                  genres  \n",
      "0            Action|Crime|Drama|Thriller  \n",
      "1                        Animation|Drama  \n",
      "2            Comedy|Crime|Drama|Thriller  \n",
      "3                                  Drama  \n",
      "4                 Animation|Comedy|Drama  \n",
      "5                   Crime|Drama|Thriller  \n",
      "6                   Crime|Drama|Thriller  \n",
      "7                 Drama|Romance|Thriller  \n",
      "8  Animation|Comedy|Drama|Romance|Sci-Fi  \n",
      "9     Adventure|Animation|Children|Drama  \n"
     ]
    }
   ],
   "source": [
    "sorted_index = np.argsort(-y_p,axis=0).reshape(-1).tolist()  #- to get largest rating first\n",
    "sorted_ypu   = y_p[sorted_index]\n",
    "sorted_items = item_vecs[sorted_index]\n",
    "sorted_user  = user_vecs[sorted_index]\n",
    "    \n",
    "y_p, user, item, movie_dict = sorted_ypu, sorted_user, sorted_items, movie_dict\n",
    "\n",
    "maxcount=10\n",
    "count = 0\n",
    "movies_listed = defaultdict(int)\n",
    "disp = [[\"y_p\", \"movie id\", \"rating ave\", \"title\", \"genres\"]]\n",
    "\n",
    "for i in range(0, y_p.shape[0]):\n",
    "    if count == maxcount:\n",
    "        break\n",
    "    count += 1\n",
    "    movie_id = item[i, 0].astype(int)\n",
    "    if movie_id in movies_listed:\n",
    "        continue\n",
    "    movies_listed[movie_id] = 1\n",
    "    disp.append([y_p[i, 0], item[i, 0].astype(int), item[i, 2].astype(float),\n",
    "                movie_dict[movie_id]['title'], movie_dict[movie_id]['genres']])\n",
    "\n",
    "df_predictions = pd.DataFrame(disp[1:], columns=disp[0])\n",
    " \n",
    "print(df_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
